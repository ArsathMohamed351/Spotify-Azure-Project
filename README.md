# ğŸš€ Azure Data Factory Incremental Data Ingestion Pipeline

## ğŸ“Œ Project Overview

This project demonstrates a **realâ€‘world incremental data ingestion pipeline** built using **Azure Data Factory (ADF)**. The pipeline efficiently loads only **new or changed data** from **Azure SQL Database** into **Azure Data Lake Storage** using a CDCâ€‘style approach. It is fully parameterized, reusable, and versionâ€‘controlled using **GitHub integration**.

The goal of this project is to showcase **productionâ€‘ready data engineering practices** such as incremental loading, looping over multiple tables, and clean data storage formats.

---

## ğŸ—ï¸ Architecture Overview

**Source:** Azure SQL Database
**Orchestration:** Azure Data Factory
**Storage:** Azure Data Lake (Parquet format)
**Version Control:** GitHub

**Highâ€‘level Flow:**

1. Identify the last loaded CDC value
2. Fetch only new records from the source table
3. Load data incrementally into Data Lake
4. Loop through multiple tables using a single pipeline
5. Skip processing when no new data is available

---

## ğŸ”„ Pipeline Features

* âœ… Incremental data loading using CDC logic
* âœ… Parameterized pipeline for dynamic table ingestion
* âœ… **ForEach activity** to process multiple tables
* âœ… Conditional checks to avoid empty data loads
* âœ… Data stored in **Parquet format** for efficiency
* âœ… GitHubâ€‘integrated ADF for version control

---

## ğŸ“‚ Repository Structure

```
ADF-Incremental-Ingestion/
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ AzureSqlTable.json
â”‚   â”œâ”€â”€ Parquet_dynamic.json
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ Incremental_ingestion.json
â”‚   â”œâ”€â”€ Incremental_Looping.json
â”‚
â”œâ”€â”€ linkedServices/
â”‚   â”œâ”€â”€ AzureSqlDatabase.json
â”‚   â”œâ”€â”€ AzureDataLake.json
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ pipeline_run.png
â”‚   â”œâ”€â”€ foreach_activity.png
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Pipeline Explanation

### 1ï¸âƒ£ Incremental_Ingestion Pipeline

* Retrieves the **maximum CDC value** from the target
* Filters source data based on the last processed value
* Copies only new records to Data Lake

### 2ï¸âƒ£ Incremental_Looping Pipeline

* Uses **ForEach activity**
* Accepts an array of table metadata as input
* Calls the incremental pipeline for each table

---

## ğŸ§ªParameter Input

```json
[
  {
    "schema" : "dbo",
    "table" : "DimUser",
    "cdc_col" : "updated_at",
    "from_date" : ""
  },
  {
    "schema" : "dbo",
    "table" : "DimTrack",
    "cdc_col" : "updated_at",
    "from_date" : ""
  },
  {
    "schema" : "dbo",
    "table" : "DimDate",
    "cdc_col" : "date",
    "from_date" : ""
  },
  {
    "schema" : "dbo",
    "table" : "DimArtist",
    "cdc_col" : "updated_at",
    "from_date" : ""
  },
  {
    "schema" : "dbo",
    "table" : "FactStream",
    "cdc_col" : "stream_timestamp",
    "from_date" : ""
  }
]

```

---

## ğŸ“Š Dataset Details

* **Source Dataset:** Azure SQL Table (dynamic schema & table name)
* **Sink Dataset:** Parquet files in Azure Data Lake
* Supports dynamic folder paths and file names

---

## ğŸ” Version Control

* ADF is connected to **GitHub**
* All pipelines, datasets, and linked services are tracked
* Enables safe collaboration and rollback

---

## ğŸ“¸ Screenshots

<img width="1916" height="991" alt="OverAll Structure" src="https://github.com/user-attachments/assets/f372d4a9-7048-40e6-a83a-a2ea7a850735" />
<img width="1919" height="992" alt="Incremental looping" src="https://github.com/user-attachments/assets/00fca17e-0291-477b-aac3-1de60d1a180c" />
<img width="1919" height="905" alt="overall Parameters" src="https://github.com/user-attachments/assets/a8f965b2-3219-41e0-a72f-c8333052e405" />
<img width="1919" height="989" alt="Incremental Looping Parameters" src="https://github.com/user-attachments/assets/113c0fbe-5416-41dc-b7e6-67ab983f392b" />
<img width="1919" height="993" alt="Gold_DLT" src="https://github.com/user-attachments/assets/ff75544d-b940-46c6-805d-b90da7baa966" />
<img width="1919" height="988" alt="Git Configuration" src="https://github.com/user-attachments/assets/888e8d20-c149-4d32-aa95-6c4e405d67ac" />


---

## ğŸ¯ Key Learnings

* How to build scalable incremental pipelines in ADF
* How to design reusable and parameterâ€‘driven pipelines
* How to integrate GitHub with Azure Data Factory
* Best practices for productionâ€‘ready ETL pipelines

---


---

## ğŸ·ï¸ Tags

`Azure Data Factory` `Incremental Load` `CDC` `ETL` `Data Engineering` `GitHub` `Parquet`

---

â­ If you find this project useful, feel free to star the repository!
